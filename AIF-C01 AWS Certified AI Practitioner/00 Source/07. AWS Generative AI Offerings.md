

AWS generative AI services and features
Selecting transcript lines in this section will navigate to timestamp in the video
- There are a number of helpful AWS services and features that can be used to help implement generative AI workloads. And let's take a look at some of those now. We're going to start off with SageMaker Jumpstart, and this gives you access to pre-trained models for tasks like summarization and image generation. You can choose to customize the models with your own data and then deploy that through the UI or the SDK. Organizations can share both models and notebooks across their various workloads. And the data is always encrypted and it stays within your own VPC so that you can ensure privacy and security. Next, we have Amazon Bedrock, and this is a service that's designed around providing high-performing foundation models from both Amazon and other companies from a single API. And you can choose to customize the models privately with your own data using fine-tuning or retrieval augmented generation, or RAG. It is entirely serverless, so you don't have to provide any infrastructure or extra operations to go along with it. And it allows for the secure integration of Gen AI into your own applications using AWS service API endpoints. Our next feature is also part of Bedrock, and it's called PartyRock. This is a playground for building generative AI apps. And you can create applications, you could generate jokes, personalized playlists, and it's all no code. And so this can help users learn AI in an area that is familiar and easy to work with and be able to use foundation models and chaining prompts together and other cool things. Next we have Amazon Q, and this is a generative AI assistant that is designed around the acceleration of software development as well as leveraging company data. There's Q Developer for coding tasks and Q Business for business intelligence tasks. And with code generation, you can answer questions, you can connect to other business tools, and it's extraordinarily useful. It also supports the ability to create AI apps that can integrate with QuickSight. And when you are asking questions around code generation or business intelligence, it can look at your current inventory of AWS resources to help provide more customized answers. And so let's put it all together. A retail company wants to automate various business tasks using AWS AI services. They want to improve efficiency as well as provide a better customer experience. And so we start with SageMaker Jumpstart. This is going to help the data science team. They can deploy and manage AI models to predict stock demands or optimize inventory. Bedrock is going to be used for integrating the Gen AI models and allows the company to personalize customer recommendations, create custom marketing campaigns, and these models can be fine-tuned with customer purchase history data. Next, we have PartyRock, and this is what the marketing team uses to create fun, interactive, AI-based web apps without having to write code. And this is something that's really important to allow for the creative exploration of the space. Then we have Q Developer, and this is used by the IT and engineering teams to generate and debug code for new business features such as an AI chatbot. And finally, Q Business is going to connect to the company's enterprise data, inventory, sales, customer feedback that is in different repositories, and then employees can query that and retrieve insights in a way that is easily understandable.


AWS generative AI advantages and benefits
Selecting transcript lines in this section will navigate to timestamp in the video
- There are many advantages and benefits to using AWS generative AI services, and let's go through some of those now. We're going to start with accessibility. GenAI services like Bedrock and SageMaker give access to prebuilt models and easy-to-use APIs. And this means that developers of different skill levels can take advantage of those without having to build something from the ground up. Next advantage is a lower barrier to entry, and this kind of builds upon that last advantage because those pre-trained models, integrated infrastructure, all of that is already there, it makes it easier to build entire workflows and workloads without having to design everything from scratch. Next is efficiency. These are managed services. They're going to handle things like automated scaling, load balancing and security, and this is going to help the developers, data scientists, and other folks to concentrate on the business logic and the application development instead. Next advantage is cost effectiveness. You get the pay-as-you-go pricing so that you don't have to statically provision a certain amount of resources to be able to build, train, or host a specific model. You simply pay for whatever you use. And next is speed to market. Because you don't have to spend all of that time on the infrastructure, provisioning, management, operations, it makes everything else go faster in terms of the development lifecycle. Our final advantage is the ability to meet business objectives and generate business value. Because you can customize these services to varying workload types, that's going to help businesses of all sorts align their solutions in AI with the rest of their business goals and objectives. Now let's take a look at some benefits and a big one here is security. Because the rest of the AWS services outside of GenAI are also designed with security in mind, you have things like encryption in transit and at rest, proper permissions management, and a lot of features to do this in a flexible fashion to meet your requirements. Our next benefit is compliance. Because AWS is already compliant with a number of well-known frameworks, that makes a lot of the underlying infrastructure automatically compliant. Now, you still need to get your workloads certified, but a lot of the heavy lifting has already been done. Our next benefit is responsibility, and this kind of builds on the other two with the shared responsibility model. AWS is responsible for data centers, hypervisors, service API endpoints, and a number of other things so that the customers can focus on what they do best, which is to manage the actual workload and the data. And our final benefit is safety. Because there are tools like SageMaker Clarify, which give developers the ability to understand and mitigate bias, there are other offerings out there as well for dealing with transparency and explainability of models so that you can reduce bias and toxicity and hallucinations where they're not wanted.



AWS generative AI cost tradeoffs
Selecting transcript lines in this section will navigate to timestamp in the video
- When working with generative AI services in AWS, there are some cost trade-offs that need to be considered. Let's go through those now. We'll start with responsiveness. If you want higher responsiveness in terms of say, faster inference times or lower latency, that is often going to lead to using more powerful models or more powerful resources, and this will almost always lead to higher costs, and that's something that has to be taken into consideration. Next is availability. AWS offers these services and features with high availability, usually built-in across different availability zones that can accommodate outages. And this increases service uptime, service availability, but it also means that AWS has to provision more resources to make it happen, which can increase the costs. Next is redundancy, and this is similar to the previous consideration. If you want to replicate data or models across regions or availability zones or do cross-region inferencing, if you want to implement disaster recovery procedures, all of this is going to lead to multiple resources and again, increase cost. Then we have performance, and if you want to specifically reduce the latency or increase the speed of the output, you can, in some cases, provide more GPU power to make that happen. Other times, it's a matter of provisioning more throughput, but again, this is going to drive up costs. Regional coverage. AWS deploys resources, especially service API endpoints on a per-region basis. And if you want to utilize multiple regions, you're going to have to make sure that the offering is available in those regions or you're going to have to communicate cross-region, which also comes at an increased cost. Token-based pricing. All these GenAI services that use LLMs are going to charge based on token usage. And the more interactions you have, the larger the interactions that you have, that is going to increase cost. And so if you are sending full-sized documents as a context for a conversation, you're going to have to pay accordingly. Then we have provision throughput. For not just GenAI services, but other offerings, AWS gives you the ability to provision the amount of throughput that you want to receive. And when you do this, rather than paying as you go, now all of a sudden you're paying for what you've provisioned, whether you're using it or not. And finally, if you're going to create custom models on AWS, you do have a lot of flexibility around the compute resources and GPUs that are required to make that happen, but because you're using a managed service rather than something that might be sitting in your own on-prem data center, there will be a higher charge for being able to use resources that are automatically highly available and redundant and just generally higher quality user experience overall.



Question breakdown, part 1
Selecting transcript lines in this section will navigate to timestamp in the video
- Greetings, in this question breakdown, we have a scenario that involves a customer support chatbot that's being deployed into AWS. Let's go ahead and take a look at the question. A company is building a customer support chatbot using AWS Generative AI services. The goal is to deploy the solution quickly, ensure it scales with demand and minimize operational overhead. They have a small development team with limited AI expertise, and the company prefers a cost-effective solution with a fast time to market. Which of the following is the most appropriate advantage of using AWS Generative AI services for the project? And we have four answer choices here that are very different in terms of which advantage that they are explaining. And so let's just go straight into reading these answer choices and understanding them a little better so we can figure out what the correct answer should be. Let's read through our first answer choice. A, custom model development from scratch allows for full control and customization of the AI model in the context of AWS. While building custom models does give the control and customization, it also requires expertise, time, resources, which the company doesn't have. We can very likely eliminate this answer choice. B, manually managing infrastructure ensures that the AI service is fully optimized for performance and cost. And that can be a true statement, depending on how well managed the infrastructure is. But AWS provides managed services that automatically handle all of that. So why would the company want to do that on their own? C, pre-built models and easy to use APIs reduce the need for in-depth AI expertise, accelerating the time to market. A-ha, this is sounding a lot better. And by using the AWS Gen AI services that have all of this available, it means that the company doesn't have to take the time to develop the in-house expertise to do this work on their own. This feels like a more appropriate answer than the first two, but let's see about the final answer choice. Requiring a large development team ensures the AI solution can be properly maintained and scaled. Well, if you use AWS Gen AI services, a large development team isn't going to be a requirement at all. In fact, you can go with smaller, leaner teams because a lot of the infrastructure is already handled because of the ecosystem that it's in, in AWS. And so this isn't an appropriate answer either. In fact, the only answer that meets the requirements listed in the question is C.



Question breakdown, part 2
Selecting transcript lines in this section will navigate to timestamp in the video
- In this practice question, we have a scenario of a company that wants to go all in on using AWS generative AI services. Let's go ahead and read the question. A retail company wants to use AWS GenAI services to improve its operations by building AI apps, managing code development, leveraging company data for insights, and visualizing business performance. Which combination of AWS services would best meet their needs? So we have four answer choices, each of which are going to list a different combination of AWS services and features. Let's go through these answer choices one at a time and see if we can figure out if there are any outliers in terms of the services that help to eliminate an answer choice. We'll start with A. Bedrock, Lambda, Q Business, and SageMaker JumpStart. Bedrock's a good start and get your AI apps built there. Q Business helps to connect enterprise data, but then, then we hit Lambda. Lambda's not really focused on AI at all. SageMaker JumpStart is okay, but we aren't going to be able to meet all of our requirements with this answer choice. So we move on to B. Q Developer, Q Business, SageMaker JumpStart, and QuickSight. Well, Amazon Q is good. We get coding tasks, accessing enterprise data. QuickSight, can it be useful for visualization? But SageMaker JumpStart doesn't enable non-developers to create AI apps like PartyRock Playground does. So we move on. Speaking of PartyRock Playground, that's our first answer here. Then Bedrock, RDS and Lambda. Well, we got one of these, right? Everything else is going to really not meet the requirements. Well, RDS, Lambda, those don't fit. Neither of those are specific AI services and certainly not generative AI. So we move on to D. Q Developer PartyRock Playground, Bedrock, and QuickSight. So we get the help with our developers and coding. We get to be able to create AI apps without writing code. We get the customization and deployment of foundation models, and we have the ability to visualize our business performance. This answer, honestly, meets all the requirements in ways that the others don't. And so that's going to be our correct answer, D.